}
}
}
else {
print(paste0("x and y do not conform, numcol x = " dim(x)[2], ", but numcol y = ", dim(y)[2]))
}
}
Euclidean_Distance <- function(x, y){
if(dim(y)[2]==dim(x)[2]){
for (i in 1:dim(X)[1]){
for (j in 1:dim(X)[2]){
print((x[i][j]-y[j])^2)
}
}
}
else {
print(paste0("x and y do not conform, numcol x = " dim(x)[2], ", but numcol y = ", dim(y)[2]))
}
}
print(i)
Euclidean_Distance <- function(x, y){
if(dim(y)[2]==dim(x)[2]){
for (i in 1:dim(X)[1]){
for (j in 1:dim(X)[2]){
print((x[i][j]-y[j])^2)
}
}
}
else print(paste0("x and y do not conform, numcol x = " dim(x)[2], ", but numcol y = ", dim(y)[2]))
}
print(i)
Euclidean_Distance <- function(x, y){
if(dim(y)[2]==dim(x)[2]){
for (i in 1:dim(X)[1]){
for (j in 1:dim(X)[2]){
print((x[i][j]-y[j])^2)
}
}
}
else print(paste0("x and y do not conform, numcol x = " dim(x)[2], ", but numcol y = ", dim(y)[2]))
}
Euclidean_Distance <- function(x, y){
if(dim(y)[2]==dim(x)[2]) {
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
print((x[i][j]-y[j])^2)
}
}
}
else print(paste0("x and y do not conform, numcol x = " dim(x)[2], ", but numcol y = ", dim(y)[2]))
}
Euclidean_Distance <- function(x, y){
if(dim(y)[2]==dim(x)[2]) {
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
print((x[i][j]-y[j])^2)
}
}
}
else print(paste0("x and y do not conform, numcol x = ", dim(x)[2], ", but numcol y = ", dim(y)[2]))
}
y = c(0,0,0)
dim(y)
length(y)
y[2]
Euclidean_Distance <- function(x, y){
if(length(y)[2]==dim(x)[2]) {
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
print((x[i][j]-y[j])^2)
}
}
}
else print(paste0("x and y do not conform, numcol x = ", dim(x)[2], ", but numcol y = ", length(y)))
}
y2 = c(0,0)
Euclidean_Distance(X, y2)
Euclidean_Distance <- function(x, y){
if(length(y)==dim(x)[2]) {
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
print((x[i][j]-y[j])^2)
}
}
}
else print(paste0("x and y do not conform, numcol x = ", dim(x)[2], ", but numcol y = ", length(y)))
}
Euclidean_Distance(X, y2)
Euclidean_Distance(X, y)
X[1]
X[1, ]
Euclidean_Distance(X[1, ], y)
Euclidean_Distance(X[1, 1:3], y)
z = X[1, ]
dim(z)
length(z)
col(X)
X
vector(0)
vector(c(1,2,3))
rep(0, dim(X)[1])
w = rep(0, dim(X)[1])
length(w)
Euclidean_Distance <- function(x, y){
if(length(y)==dim(x)[2]) {
w = rep(0, dim(x)[1])
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
print((x[i][j]-y[j])^2)
}
}
}
else print(paste0("x and y do not conform, numcol x = ", dim(x)[2], ", but numcol y = ", length(y)))
}
Euclidean_Distance(X, y)
Euclidean_Distance <- function(x, y = rep(0, dim(x)[1])){
if(length(y)==dim(x)[2]) {
w = rep(0, dim(x)[1])
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
print((x[i][j]-y[j])^2)
}
}
}
else print(paste0("x and y do not conform, numcol x = ", dim(x)[2], ", but numcol y = ", length(y)))
}
Euclidean_Distance(X)
Euclidean_Distance <- function(x, y = rep(0, dim(x)[2])){
if(length(y)==dim(x)[2]) {
w = rep(0, dim(x)[1])
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
print((x[i][j]-y[j])^2)
}
}
}
else print(paste0("x and y do not conform, numcol x = ", dim(x)[2], ", but numcol y = ", length(y)))
}
Euclidean_Distance(X)
Euclidean_Distance <- function(x, y = rep(0, dim(x)[2])){
if(length(y)==dim(x)[2]) {
w = rep(0, dim(x)[1])
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
print((x[i,j]-y[j])^2)
}
}
}
else print(paste0("x and y do not conform, numcol x = ", dim(x)[2], ", but numcol y = ", length(y)))
}
Euclidean_Distance(X)
g = matrix(c(y = rep(0, dim(x)[2]*dim(x)[1])))
x = X
g = matrix(c(y = rep(0, dim(x)[2]*dim(x)[1])))
g
g = matrix(c(y = rep(0, dim(x)[2]*dim(x)[1])), nrow = dim(x)[1])
g
Euclidean_Distance <- function(x, y = rep(0, dim(x)[2])){
if(length(y)==dim(x)[2]) {
w = rep(0, dim(x)[1])
g = matrix(c(y = rep(0, dim(x)[2]*dim(x)[1])), nrow = dim(x)[1])
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
g[i,j] = (x[i,j]-y[j])^2
}
}
return(g)
}
else print(paste0("x and y do not conform, numcol x = ", dim(x)[2], ", but numcol y = ", length(y)))
}
Euclidean_Distance(X)
l = Euclidean_Distance(X)
l
sum(g)
g
sum(l)
sum(l, byrow)
?sum
Euclidean_Distance <- function(x, y = rep(0, dim(x)[2])){
if(length(y)==dim(x)[2]) {
w = rep(0, dim(x)[1])
g = matrix(c(y = rep(0, dim(x)[2]*dim(x)[1])), nrow = dim(x)[1])
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
g[i,j] = (x[i,j]-y[j])^2
w[i] = w[i]+[g[i,j]]
}
}
w = sqrt(w)
return(w)
}
else print(paste0("x and y do not conform, numcol x = ", dim(x)[2], ", but numcol y = ", length(y)))
}
Euclidean_Distance <- function(x, y = rep(0, dim(x)[2])){
if(length(y)==dim(x)[2]) {
w = rep(0, dim(x)[1])
g = matrix(c(y = rep(0, dim(x)[2]*dim(x)[1])), nrow = dim(x)[1])
for (i in 1:dim(X)[1]) {
for (j in 1:dim(X)[2]){
g[i,j] = (x[i,j]-y[j])^2
w[i] = w[i]+g[i,j]
}
}
w = sqrt(w)
return(w)
}
else print(paste0("x and y do not conform, numcol x = ", dim(x)[2], ", but numcol y = ", length(y)))
}
m = Euclidean_Distance(X)
m
Y
X = matrix(c(0,3,0,2,0,0,0,1,3,0,1,2,-1,0,1,1,1,1), nrow=6, byrow=TRUE)
Y = c("Red", "Red", "Red", "Green", "Green", "Red")
source('~/ISLR_Labs/MyWork/Euclidean_Distance.R')
A = matrix(c(10, 10, 10), nrow=1)
Euclidean_Distance(A)
source('~/.active-rstudio-document')
getwd()
current_directory = "C:\Users\Austin\Documents\ISLR_Labs\MyWork"
current_directory = replace("C:\Users\Austin\Documents\ISLR_Labs\MyWork", "\", "/")
x = 'adfadaf'
?replace
replace(x, "a","b")
fp <- readClipboard()
fp <- readClipboard()
setwd(fp)
Euclidean_Distance(A)
source("Euclidean_Distance.R")
Euclidean_Distance(A)
A = matrix(c(10, 10, 10), nrow=1)
A
Euclidean_Distance(A)
Euclidean_Distance(x = A)
source('~/ISLR_Labs/MyWork/Euclidean_Distance.R')
source("Euclidean_Distance.R")
Euclidean_Distance(A)
rnorm(10)
A = matrix(c(rnorm(1000)*10), nrow=1000/50)
Euclidean_Distance(A)
A = matrix(c(rnorm(999)*10), nrow=333)
Euclidean_Distance(A)
X = matrix(c(0,3,0,2,0,0,0,1,3,0,1,2,-1,0,1,1,1,1), nrow=6, byrow=TRUE)
Y = c("Red", "Red", "Red", "Green", "Green", "Red")
Euclidean_Distance(X)
!pwd
!dir()
!dir
getwd()
file.choose
file.choose()
input_filepath = file.choose()
?read.csv2
read.csv(file = input_filepath)
College_data = read.csv(file = input_filepath)
fix(College_data)
college = read.csv(file = input_filepath)
fix(college)
rownames(college)=college[ ,1]
fix(college)
college = college[ , -1]
fix(college)
college[rownames("Harvard")]
college
fix(college)
?subset
H = subset(college, rownames == "Harvard")
fix(college)
H = subset(college, row.names == "Harvard")
?subset
fix(college)
college2 = college
college2['pct_accpt'] = college2$Accept/college2$Apps
college2 = college2[order(-pct_accpt),]
head(college2)
college2$pct_accpt = college2$Accept/college2$Apps
college2 = college2[order(-pct_accpt),]
college2 = college2[order(-college2$pct_accpt),]
head(college2)
college3 = college2[order(college2$pct_accpt),]
head(college3)
my_subset = college2[c("Harvard University", "George Washington University"),
]
my_subset
# c)
## i.  produce a numerical summary
summary(college)
pairs(college)
pairs(college[ , 1:10])
college(order[-college$Grad.Rate])
college(order[, -college$Grad.Rate])
order(college, college$Grad.Rate)
## iii.  Use the plot() function to produce side-by-side boxplots of Outstate versus Private.
plot(college$Outstate ~ college$Private)
?subset
subset(college, Outstate > 20000)
Elite = rep("No", nrow(college))
Elite
Elite[college$Top10perc > 50] = "Yes"
Elite
Elite = as.factor(Elite)
Elite
college = data.frame(college, Elite)
summary(Elite)
subset(college, Elite = "Yes")
college = data.frame(college, Elite)
subset(college, Elite = "Yes")
subset(college, Elite == "Yes")
head(college)
college[ , -c("Elite.1")]
college[ , -c("Elite")]
college[ , -20]
summary(Elite)  # There are 78 elite universities, and 699 that are not elite.
college$Elite.1
college = college[ , -21]
head(college)
dim(college)
head(college[ , 20])
college = college[ , -20]
dim(college)
head(college)
plot(college$Elite ~ college$Outstate)
plot(college$Outstate ~ college$Elite)
hist(college)
hist(college$Top10perc, college$Outstate)
hist(college$Top10perc ~ college$Outstate)
?hist
hist(college$Top10perc)
hist(college$Elite)
hist(college$Outstate)
hist(college$Room.Board)
hist(college$Expend)
par(mfrow = c(2, 2))
hist(college$Top10perc)
hist(college$Outstate)
hist(college$Room.Board)
hist(college$Expend)
install.packages("ISLR")
library(ISLR)
cor(weekly_directionless)
# a  Do some numerical and graphical summaries of the data.  Do there appear to be any patterns?
names(Weekly)
dim(Weekly)
summary(Weekly)
weekly_directionless = subset(Weekly, select = -c(Direction))
weekly_directionless
cor(weekly_directionless)
pairs(weekly)
library(ISLR)
# a  Do some numerical and graphical summaries of the data.  Do there appear to be any patterns?
names(Weekly)
dim(Weekly)
summary(Weekly)
weekly_directionless = subset(Weekly, select = -c(Direction))
weekly_directionless
cor(weekly_directionless)
head(Weekly)
plot(Weekly$Volume)
subset(Weekly, Volume > 9)
subset(Weekly, Year == max(Year), select = c(Volume))
test_year = Weekly$Year
max_year = max(test_year)
# Will continue data exploration next time.
pairs(weekly)
# Will continue data exploration next time.
pairs(Weekly)
?glm
glm.weekly = glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Weekly, family = binomial)
summary(glm.weekly)
glm.probs = predict(glm.weekly, type = "response")
glm.probs[1:10]
contrasts(Direction)
library(ISLR)
contrasts(Direction)
contrasts(Direction)
Direction
contrasts(Weekly$Direction)
?contrasts
my_test_vector = c("suitor", "wife", "maiden", "husband", "suitor", "wife", "maiden", "bouncer")
contrasts(my_test_vector)
as.factor(my_test_vector)
contrasts(as.factor(my_test_vector))
dim(Weekly)
length(Weekly)
width(Weekly)
nrow(Weekly)
glm.pred = rep("Down", nrow(Weekly))
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Weekly$Direction)
mean(glm.pred == Weekly$Direction)
train = (Weekly$Year < 2009)
Weekly.2005 = Weekly[!train]
Weekly.2005 = Weekly[!train, ]
dim(Weekly.2005)
Direction.2005 = Weekly$Direction[!train]
glm.fits = glm(Direction ~ Lag2, data = Weekly, family = binomial, subset = train)
glm.probs = predict(glm.fits, Weekly.2005, type = "response")
glm.pred = rep("Down", nrow(Weekly.2005))
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction.2005)
train = (Weekly$Year < 2009)
Weekly.2005 = Weekly[!train, ]
dim(Weekly.2009)
Direction.2009 = Weekly$Direction[!train]
glm.fits = glm(Direction ~ Lag2, data = Weekly, family = binomial, subset = train)
glm.probs = predict(glm.fits, Weekly.2009, type = "response")
glm.pred = rep("Down", nrow(Weekly.2009))
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction.2009)
train = (Weekly$Year < 2009)
Weekly.2009 = Weekly[!train, ]
dim(Weekly.2009)
Direction.2009 = Weekly$Direction[!train]
glm.fits = glm(Direction ~ Lag2, data = Weekly, family = binomial, subset = train)
glm.probs = predict(glm.fits, Weekly.2009, type = "response")
glm.pred = rep("Down", nrow(Weekly.2009))
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction.2009)
mean(glm.pred == Direction.2009)
lda.fit = lda(Direction ~ Lag2, data = Weekly, family = binomial, subset = train)
library(MASS)
lda.fit = lda(Direction ~ Lag2, data = Weekly, family = binomial, subset = train)
lda.fit
lda.pred = predict(lda.fit, Weekly.2009)
names(lda.pred)
lda.class = lda.pred$class
table(lda.class, Weekly.2009)
lda.class
dim(lda.class)
length(lda.class)
length(Weekly.2009)
dim(Weekly.2009)
table(lda.class, Weekly.2009)
table(lda.class, Weekly.2009$Direction)
table(lda.class, Direction.2009)
mean(lda.class == Direction.2009)
qda.fit = qda(Direction ~ Lag2, data = Weekly, family = binomial, subset = train)
qda.fit
qda.pred = predict(qda.fit, Weekly.2009)
names(qda.pred)
qda.class = qda.pred$class
length(qda.class)
length(Weekly.2009)
dim(Weekly.2009)
table(qda.class, Direction.2009)
mean(qda.class == Direction.2009)   # 62.5% ; This is identical in accuracy to the logistic regression.
# The confusion matrix is identical as well.
library(class)
train.X = cbind(Lag2)[train, ]
train.X = cbind(Weekly$Lag2)[train, ]
test.X = cbind(Weekly$Lag2)[!train, ]
train.Direction = Direction[train]
train.Direction = Weekly$Direction[train]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k=1)
library(class)
train.X = Weekly$Lag2[train, ]
test.X = Weekly$Lag2[!train, ]
train.X = Weekly$Lag2[train]
test.X = Weekly$Lag2[!train]
train.Direction = Weekly$Direction[train]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k=1)
dim(train.X)
dim(test.X)
library(class)
train.X = c(Weekly$Lag2)[train]
test.X = c(Weekly$Lag2)[!train]
train.Direction = Weekly$Direction[train]
dim(train.X)
dim(test.X)
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k=1)
length(train.X)
train.X
test.X
train.X = as.matrix((Weekly$Lag2)[train])
test.X = as.matrix((Weekly$Lag2)[!train])
train.Direction = Weekly$Direction[train]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k=1)
table(knn.pred, Direction.2009)
table(knn.pred, Direction.2009)[1,1]
output = table(knn.pred, Direction.2009)
(output[1, 1] + output[2, 2]) / sum(Output)
output = table(knn.pred, Direction.2009)
(output[1, 1] + output[2, 2]) / sum(Output)
(output[1, 1] + output[2, 2]) / sum(output)
knn.pred2 = knn(train.X, test.X, train.Direction, k=2)
knn.pred3 = knn(train.X, test.X, train.Direction, k=3)
knn.pred4 = knn(train.X, test.X, train.Direction, k=4)
knn.pred5 = knn(train.X, test.X, train.Direction, k=5)
table(knn.pred2, Direction.2009)
output = table(knn.pred2, Direction.2009)
(output[1, 1] + output[2, 2]) / sum(output)
table(knn.pred3, Direction.2009)
output = table(knn.pred3, Direction.2009)
(output[1, 1] + output[2, 2]) / sum(output)
table(knn.pred4, Direction.2009)
output = table(knn.pred4, Direction.2009)
(output[1, 1] + output[2, 2]) / sum(output)
table(knn.pred5, Direction.2009)
output = table(knn.pred5, Direction.2009)
(output[1, 1] + output[2, 2]) / sum(output)
knn.pred5 = knn(train.X, test.X, train.Direction, k=6)
table(knn.pred6, Direction.2009)
output = table(knn.pred6, Direction.2009)
(output[1, 1] + output[2, 2]) / sum(output)  # 51.9%
knn.pred5 = knn(train.X, test.X, train.Direction, k=5)
knn.pred6 = knn(train.X, test.X, train.Direction, k=6)
table(knn.pred6, Direction.2009)
output = table(knn.pred6, Direction.2009)
(output[1, 1] + output[2, 2]) / sum(output)  # 51.9%
